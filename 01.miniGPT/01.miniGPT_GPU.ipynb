{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIOXoY1xgiww"
      },
      "source": [
        "# Train a miniGPT language model with JAX\n",
        "\n",
        "This tutorial demonstrates how to use JAX, [Flax NNX](http://flax.readthedocs.io) and [Optax](http://optax.readthedocs.io) for language model (pre)training on GPU. It was originally inspired by the [Keras miniGPT tutorial](https://keras.io/examples/generative/text_generation_with_miniature_gpt/).\n",
        "\n",
        "If you are new to JAX for AI, check out the [introductory tutorial](https://jax-ai-stack.readthedocs.io/en/latest/getting_started_with_jax_for_AI.html), which covers neural network building with [Flax NNX](https://flax.readthedocs.io/en/latest/nnx_basics.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTmz5Cbco7n_"
      },
      "source": [
        "## Setup\n",
        "\n",
        "JAX installation is covered in [this guide](https://jax.readthedocs.io/en/latest/installation.html) on the JAX documentation site. We will use [Tiktoken](https://github.com/openai/tiktoken) for tokenization and [Grain](https://google-grain.readthedocs.io/en/latest/index.html) for data loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMsOIc7ouCO",
        "outputId": "09676b73-dff6-4fce-9f3c-1b32ec34605b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq tiktoken grain matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcji_799n4eA"
      },
      "source": [
        "Check the available JAX devices, or [`jax.Device`](https://jax.readthedocs.io/en/latest/_autosummary/jax.Device.html), with [`jax.devices()`](https://jax.readthedocs.io/en/latest/_autosummary/jax.devices.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LS9sQEY3n0mB"
      },
      "outputs": [],
      "source": [
        "import jax, os\n",
        "jax.devices()\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHzJ_bokoovZ"
      },
      "source": [
        "Get the [TinyStories dataset from Hugging Face](https://huggingface.co/datasets/roneneldan/TinyStories). We only use the training split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUjQsgQEmI1N",
        "outputId": "99ff17a1-05bb-4487-963c-884aae0eb2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-13 07:41:51--  https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-valid.txt?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.102.128, 3.165.102.22, 3.165.102.58, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.102.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/645e8da96320b0efe40ade7a/a41b122d3e83c4f0e375e4f6df4ebe55a9a4692c9b6043ca6356d740e75cd312?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250813%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250813T074152Z&X-Amz-Expires=3600&X-Amz-Signature=8764f4c2b408b45a01675908e48da4d42a4a650dfd3b97c652355a6f8f378dc1&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27TinyStories-valid.txt%3B+filename%3D%22TinyStories-valid.txt%22%3B&response-content-type=text%2Fplain&x-id=GetObject&Expires=1755074512&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NTA3NDUxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDVlOGRhOTYzMjBiMGVmZTQwYWRlN2EvYTQxYjEyMmQzZTgzYzRmMGUzNzVlNGY2ZGY0ZWJlNTVhOWE0NjkyYzliNjA0M2NhNjM1NmQ3NDBlNzVjZDMxMioifV19&Signature=cftilMonG8Cj%7EXY640xF522AKoKhOSocgCCudojRlVzLV2-1V70oxbiBxwpRpq4NOL9ohgrfQbTLkHV8f9Qp0JauWR0VBzVQKD0GMx8pAPKYUDA4qNnSMbiqZt3wfx--257h874thanfC8bAsRvsfXJ8HMM3hIREt5RmJzkvrLuhBR22ysPMcngMsAXZ6BWQbb0bYnbE5-OMhJYMgGCf1XHWir09SudkHV30Sw0u%7ErQJpmd5Ou3-bMivZNiT9Bu3lnCPUNBeP3%7EDUDs3vmymXcUISNGL2NQVKvRJ9gn-QP0mpE6mQU7ln-YnKDQOVDQDUydnm7jsytiNoKTKsnFRYg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-08-13 07:41:52--  https://cas-bridge.xethub.hf.co/xet-bridge-us/645e8da96320b0efe40ade7a/a41b122d3e83c4f0e375e4f6df4ebe55a9a4692c9b6043ca6356d740e75cd312?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250813%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250813T074152Z&X-Amz-Expires=3600&X-Amz-Signature=8764f4c2b408b45a01675908e48da4d42a4a650dfd3b97c652355a6f8f378dc1&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27TinyStories-valid.txt%3B+filename%3D%22TinyStories-valid.txt%22%3B&response-content-type=text%2Fplain&x-id=GetObject&Expires=1755074512&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NTA3NDUxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDVlOGRhOTYzMjBiMGVmZTQwYWRlN2EvYTQxYjEyMmQzZTgzYzRmMGUzNzVlNGY2ZGY0ZWJlNTVhOWE0NjkyYzliNjA0M2NhNjM1NmQ3NDBlNzVjZDMxMioifV19&Signature=cftilMonG8Cj%7EXY640xF522AKoKhOSocgCCudojRlVzLV2-1V70oxbiBxwpRpq4NOL9ohgrfQbTLkHV8f9Qp0JauWR0VBzVQKD0GMx8pAPKYUDA4qNnSMbiqZt3wfx--257h874thanfC8bAsRvsfXJ8HMM3hIREt5RmJzkvrLuhBR22ysPMcngMsAXZ6BWQbb0bYnbE5-OMhJYMgGCf1XHWir09SudkHV30Sw0u%7ErQJpmd5Ou3-bMivZNiT9Bu3lnCPUNBeP3%7EDUDs3vmymXcUISNGL2NQVKvRJ9gn-QP0mpE6mQU7ln-YnKDQOVDQDUydnm7jsytiNoKTKsnFRYg__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.125, 18.155.68.46, 18.155.68.14, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19447282 (19M) [text/plain]\n",
            "Saving to: ‘TinyStories-train.txt’\n",
            "\n",
            "TinyStories-train.t 100%[===================>]  18.55M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-08-13 07:41:52 (394 MB/s) - ‘TinyStories-train.txt’ saved [19447282/19447282]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-valid.txt?download=true -O TinyStories-train.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKE2uUafLobI"
      },
      "source": [
        "Import the necessary modules, including JAX NumPy, Flax NNX, Optax, Grain, pandas, and Tiktoken:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MKYFNOhdLq98"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax.nnx as nnx\n",
        "import optax\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import grain.python as pygrain\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyt7MV6prz1"
      },
      "source": [
        "## Define the miniGPT model with Flax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZKdhNo98NgG"
      },
      "source": [
        "We will use the GPT-2 tokenizer from the [Tiktoken](https://github.com/openai/tiktoken) library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iWbkk1V7-Isg"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define the model."
      ],
      "metadata": {
        "id": "OfR1dX3qA7_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z0p-IHurrB9i"
      },
      "outputs": [],
      "source": [
        "# Define a triangular mask for causal attention with `jax.numpy.tril` and `jax.numpy.ones`.\n",
        "def causal_attention_mask(seq_len):\n",
        "    return jnp.tril(jnp.ones((seq_len, seq_len)))\n",
        "\n",
        "class TransformerBlock(nnx.Module):\n",
        "    \"\"\" A single Transformer block.\n",
        "\n",
        "    Each Transformer block processes input sequences via self-attention and feed-forward networks.\n",
        "\n",
        "    Args:\n",
        "        embed_dim (int): Embedding dimensionality.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        ff_dim (int): Dimensionality of the feed-forward network.\n",
        "        rngs (flax.nnx.Rngs): A Flax NNX stream of JAX PRNG keys.\n",
        "        rate (float): Dropout rate. Defaults to 0.1.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, *, rngs: nnx.Rngs, rate: float = 0.1):\n",
        "        # Multi-Head Attention (MHA) with `flax.nnx.MultiHeadAttention`.\n",
        "        self.mha = nnx.MultiHeadAttention(num_heads=num_heads,\n",
        "                                          in_features=embed_dim,\n",
        "                                          rngs=rngs)\n",
        "        # The first dropout with `flax.nnx.Dropout`.\n",
        "        self.dropout1 = nnx.Dropout(rate=rate)\n",
        "        # First layer normalization with `flax.nnx.LayerNorm`.\n",
        "        self.layer_norm1 = nnx.LayerNorm(epsilon=1e-6,\n",
        "                                         num_features=embed_dim,\n",
        "                                         rngs=rngs)\n",
        "        # The first linear transformation for the feed-forward network with `flax.nnx.Linear`.\n",
        "        self.linear1 = nnx.Linear(in_features=embed_dim,\n",
        "                                  out_features=ff_dim,\n",
        "                                  rngs=rngs)\n",
        "        # The second linear transformation for the feed-forward network with `flax.nnx.Linear`.\n",
        "        self.linear2 = nnx.Linear(in_features=ff_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  rngs=rngs)\n",
        "        # The second dropout with `flax.nnx.Dropout`.\n",
        "        self.dropout2 = nnx.Dropout(rate=rate)\n",
        "        # Second layer normalization with `flax.nnx.LayerNorm`.\n",
        "        self.layer_norm2 = nnx.LayerNorm(epsilon=1e-6,\n",
        "                                         num_features=embed_dim,\n",
        "                                         rngs=rngs)\n",
        "\n",
        "\n",
        "    # Apply the Transformer block to the input sequence.\n",
        "    def __call__(self, inputs, training: bool = False):\n",
        "        input_shape = inputs.shape\n",
        "        _, seq_len, _ = input_shape\n",
        "\n",
        "        # Instantiate the causal attention mask.\n",
        "        mask = causal_attention_mask(seq_len)\n",
        "\n",
        "        # Apply Multi-Head Attention with the causal attention mask.\n",
        "        attention_output = self.mha(\n",
        "            inputs_q=inputs,\n",
        "            mask=mask,\n",
        "            decode=False\n",
        "        )\n",
        "        # Apply the first dropout.\n",
        "        attention_output = self.dropout1(attention_output, deterministic=not training)\n",
        "        # Apply the first layer normalization.\n",
        "        out1 = self.layer_norm1(inputs + attention_output)\n",
        "\n",
        "        # The feed-forward network.\n",
        "        # Apply the first linear transformation.\n",
        "        ffn_output = self.linear1(out1)\n",
        "        # Apply the ReLU activation with `flax.nnx.relu`.\n",
        "        ffn_output = nnx.relu(ffn_output)\n",
        "        # Apply the second linear transformation.\n",
        "        ffn_output = self.linear2(ffn_output)\n",
        "        # Apply the second dropout.\n",
        "        ffn_output = self.dropout2(ffn_output, deterministic=not training)\n",
        "        # Apply the second layer normalization and return the output of the Transformer block.\n",
        "        return self.layer_norm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(nnx.Module):\n",
        "    \"\"\" Combines token embeddings (words in an input sentence) with\n",
        "    positional embeddings (the position of each word in a sentence).\n",
        "\n",
        "    Args:\n",
        "        maxlen (int): Matimum sequence length.\n",
        "        vocal_size (int): Vocabulary size.\n",
        "        embed_dim (int): Embedding dimensionality.\n",
        "        rngs (flax.nnx.Rngs): A Flax NNX stream of JAX PRNG keys.\n",
        "    \"\"\"\n",
        "    def __init__(self, maxlen: int, vocab_size: int, embed_dim: int, *, rngs: nnx.Rngs):\n",
        "        # Initialize token embeddings (using `flax.nnx.Embed`).\n",
        "        # Each unique word has an embedding vector.\n",
        "        self.token_emb = nnx.Embed(num_embeddings=vocab_size, features=embed_dim, rngs=rngs)\n",
        "        # Initialize positional embeddings (using `flax.nnx.Embed`).\n",
        "        self.pos_emb = nnx.Embed(num_embeddings=maxlen, features=embed_dim, rngs=rngs)\n",
        "\n",
        "    # Takes a token sequence (integers) and returns the combined token and positional embeddings.\n",
        "    def __call__(self, x):\n",
        "        # Generate a sequence of positions for the input tokens.\n",
        "        positions = jnp.arange(0, x.shape[1])[None, :]\n",
        "        # Look up the positional embeddings for each position in the input sequence.\n",
        "        position_embedding = self.pos_emb(positions)\n",
        "        # Look up the token embeddings for each token in the input sequence.\n",
        "        token_embedding = self.token_emb(x)\n",
        "        # Combine token and positional embeddings.\n",
        "        return token_embedding + position_embedding\n",
        "\n",
        "class MiniGPT(nnx.Module):\n",
        "    \"\"\" A miniGPT transformer model, inherits from `flax.nnx.Module`.\n",
        "\n",
        "    Args:\n",
        "        maxlen (int): Maximum sequence length.\n",
        "        vocab_size (int): Vocabulary size.\n",
        "        embed_dim (int): Embedding dimensionality.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        feed_forward_dim (int): Dimensionality of the feed-forward network.\n",
        "        num_transformer_blocks (int): Number of transformer blocks. Each block contains attention and feed-forward networks.\n",
        "        rngs (nnx.Rngs): A Flax NNX stream of JAX PRNG keys.\n",
        "    \"\"\"\n",
        "    # Initialize miniGPT model components.\n",
        "    def __init__(self, maxlen: int, vocab_size: int, embed_dim: int, num_heads: int, feed_forward_dim: int, num_transformer_blocks: int, rngs: nnx.Rngs):\n",
        "        # Initiliaze the `TokenAndPositionEmbedding` that combines token and positional embeddings.\n",
        "        self.embedding_layer = TokenAndPositionEmbedding(\n",
        "                    maxlen, vocab_size, embed_dim, rngs=rngs\n",
        "                )\n",
        "        # Create a list of `TransformerBlock` instances.\n",
        "        # Each block processes input sequences using attention and feed-forward networks.\n",
        "        self.transformer_blocks = [TransformerBlock(\n",
        "            embed_dim, num_heads, feed_forward_dim, rngs=rngs\n",
        "        ) for _ in range(num_transformer_blocks)]\n",
        "        # Initialize the output `flax.nnx.Linear` layer producing logits over the vocabulary for next-token prediction.\n",
        "        self.output_layer = nnx.Linear(in_features=embed_dim,\n",
        "                                       out_features=vocab_size,\n",
        "                                       rngs=rngs)\n",
        "\n",
        "    def __call__(self, inputs, training: bool = False):\n",
        "        # Pass the input tokens through the `embedding_layer` to get token embeddings.\n",
        "        # Apply each transformer block sequentially to the embedded input, use the `training` flag for the behavior of `flax.nnx.Dropout`.\n",
        "        x = self.embedding_layer(inputs)\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            x = transformer_block(x, training=training)\n",
        "        # Pass the output of the transformer blocks through the output layer,\n",
        "        # and obtain logits for each token in the vocabulary (for next token prediction).\n",
        "        outputs = self.output_layer(x)\n",
        "        return outputs\n",
        "\n",
        "    @nnx.jit\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = jax.lax.top_k(logits, k=top_k)\n",
        "        logits = nnx.softmax(logits)\n",
        "        return jax.random.choice(jax.random.PRNGKey(0), indices, p=logits)\n",
        "\n",
        "    @nnx.jit\n",
        "    def generate_step(self, padded_tokens, sample_index):\n",
        "        logits = self(padded_tokens)\n",
        "        next_token = self.sample_from(logits[0][sample_index])\n",
        "        return next_token\n",
        "\n",
        "    def generate_text(self, max_tokens, start_tokens):\n",
        "        generated = []\n",
        "        print(tokenizer.decode(start_tokens), flush=True, end='')\n",
        "        for i in range(max_tokens):\n",
        "            sample_index = len(start_tokens) + len(generated) - 1\n",
        "\n",
        "            padded_tokens = jnp.array((start_tokens + generated + [0] * (maxlen - len(start_tokens) - len(generated))))[None, :]\n",
        "            next_token = int(self.generate_step(padded_tokens, sample_index))\n",
        "            if next_token == tokenizer.encode('<|endoftext|>', allowed_special={'<|endoftext|>'})[0]:\n",
        "              break\n",
        "            generated.append(next_token)\n",
        "            # decode and print next_token\n",
        "            print(tokenizer.decode([next_token]), flush=True, end='')\n",
        "        return tokenizer.decode(start_tokens + generated)\n",
        "\n",
        "# Creates the miniGPT model with 4 transformer blocks.\n",
        "def create_model(rngs):\n",
        "    return MiniGPT(maxlen, vocab_size, embed_dim, num_heads, feed_forward_dim, num_transformer_blocks=4, rngs=rngs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igX_eoGNMTGR"
      },
      "source": [
        "Set some hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GRhiDsCrMZRp"
      },
      "outputs": [],
      "source": [
        "vocab_size = tokenizer.n_vocab\n",
        "num_transformer_blocks = 8\n",
        "maxlen = 256\n",
        "embed_dim = 256\n",
        "num_heads = 8\n",
        "feed_forward_dim = 256\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "top_k = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1ci-HyMspJ"
      },
      "source": [
        "## Loading and preprocessing the data\n",
        "\n",
        "Data loading and preprocessing with [Grain](https://github.com/google/grain)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rGUFsn1GMuzh"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TextDataset:\n",
        "    data: list\n",
        "    maxlen: int\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        # Use Tiktoken for tokenization\n",
        "        encoding = tokenizer.encode(self.data[idx], allowed_special={'<|endoftext|>'})[:self.maxlen]  # Tokenize and truncate\n",
        "        return encoding + [0] * (self.maxlen - len(encoding))  # Pad to maxlen\n",
        "\n",
        "def load_and_preprocess_data(file_path, batch_size, maxlen):\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "      text = f.read()\n",
        "\n",
        "    stories = text.split('<|endoftext|>')\n",
        "    stories = [story+'<|endoftext|>' for story in stories if story.strip()]\n",
        "    df = pd.DataFrame({'text': stories})\n",
        "    data = df['text'].dropna().tolist()\n",
        "    dataset = TextDataset(data, maxlen)\n",
        "\n",
        "    sampler = pygrain.IndexSampler(\n",
        "        len(dataset),\n",
        "        shuffle=False,\n",
        "        seed=42,\n",
        "        shard_options=pygrain.NoSharding(),\n",
        "        num_epochs=num_epochs,\n",
        "    )\n",
        "\n",
        "    dl = pygrain.DataLoader(\n",
        "        data_source=dataset,\n",
        "        sampler=sampler,\n",
        "        operations=[pygrain.Batch(batch_size=batch_size, drop_remainder=True)],\n",
        "    )\n",
        "\n",
        "    return dl\n",
        "\n",
        "text_dl = load_and_preprocess_data('TinyStories-train.txt', batch_size, maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVSD8KSM1um"
      },
      "source": [
        "## Defining the loss function and training step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8rRuTmABNV4b"
      },
      "outputs": [],
      "source": [
        "# Defines the loss function using `optax.softmax_cross_entropy_with_integer_labels`.\n",
        "def loss_fn(model, batch):\n",
        "    logits = model(batch[0])\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch[1]).mean()\n",
        "    return loss, logits\n",
        "\n",
        "# Define the training step with the `flax.nnx.jit` transformation decorator.\n",
        "@nnx.jit\n",
        "def train_step(model: MiniGPT, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
        "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
        "    (loss, logits), grads = grad_fn(model, batch)\n",
        "    metrics.update(loss=loss, logits=logits, lables=batch[1])\n",
        "    optimizer.update(grads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5um2vkeUNckm"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Start training. It takes ~50 minutes on Colab.\n",
        "\n",
        "Note that for data parallel, we are sharding the training data along the `batch` axis using `jax.device_put` with `NamedeSharding`.\n",
        "\n",
        "We are also using the `jax.vmap` transformation to produce the target sequences faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysl6CsfENeJN",
        "outputId": "eab9e0a8-b4b6-41c4-a3ec-73b7cea57571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial generated text:\n",
            "Once upon a time infiltrated abunduitvicval methamphetamine360360 LevelsFortGb bonds {} pathwaysickey northwest� {} stoppingcre� {} scenario Vegan Captain Analysis northwest nomination {} FS {} commentary northwest See {} Woman {}Except FS constitute perished {} {} {}Nick nominationExcept {}Nick FS {} stopping Analysis Whites {} Whitescre lore Levelsval {} See gearfingerLucaped offence elder Types {}edIninkinguser FS Bruce Pell {} Levels FS {} {} Levels(- nomination FSShoulduit FS nomination Shattered deline emanc Levels Whites {} Whites {} Bruce {} FS {} {} Analysis unite Blackburn FSuesecarb firepower grasped nomination nomination graspedproblem Tang FS purple FS {} {} Levelsphalt {} {} Bruce {} BruceLucydia {} {} FS {}acial helic FS {} FS constitute perished {}absor northwestroidraviolet visceralproblem {} {} Analysis {}absor Broadcasting FS constitute {} Woman nomination {} FSMuch nond {} stoppinguniversaloun constitute perished {} retire {}netlast Shattered Whites {} FS {} {} commentary reservationscre Atom transistor Tang FSintensity {} dissatisfied {} Woman Captain {} FS constitute scoring Shatteredcre description(- {} FSumbledEEE Blackburncre Atom {}scl Twin sourcing {} northwest Intercept hiding {} escalation wil {} northwestroidExceptBT {} {} Woman tread escalation treasures {}scl FSMuch FS nominationscluces {}absor struggleuniversal {} {} dissatisfied FS {}absor survivoreteenth Levels Whites marscre Judges Judges Judges\n",
            "\n",
            "Step 50, Loss: 5.311977386474609, Elapsed Time: 47.17 seconds\n",
            "Generated text:\n",
            "Once upon a time a was a was was,,,, was,,,,.,.,.,.,.,,..,.,.,.,.,.,.,...,.,....,..,.....................................\n",
            " the.\n",
            " the the the the the the the the the the the the the the the the the the the the the the the the the...\n",
            " the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Judges Judges Judges\n",
            "\n",
            "Step 100, Loss: 4.001964092254639, Elapsed Time: 24.68 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named named named. She was a big. She was a big. She was so she was so she was so she was so she was so she was so happy. She wanted to her. She was so happy. She wanted to her mommy. She wanted to her mommy. She said, \"I!\n",
            "The little girl was so happy. She was so happy and said, \"I!\n",
            "The big and said, \"I!\n",
            "The little girl was very happy and her mommy. She was very happy and said, \"I!\n",
            "\n",
            "\n",
            "Step 150, Loss: 3.215121030807495, Elapsed Time: 23.81 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little boy named Timmy. Timmy was a big, he was so he was very happy. He was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so he was so! Judges Judges Judges\n",
            "\n",
            "Step 200, Loss: 2.983671188354492, Elapsed Time: 25.89 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her mom. She loved to play with her mom. She was a big, Lily's mom. She was a big, Lily's mom. She was too. She was too.\n",
            "\"I'm sorry, \"I'm sorry, \"I'm sorry, \"I want to the park. She said, \"I'm sorry, \"I'm sorry, \"I'm sorry, \"I want to the park. She said, \"I'm sorry.\"\n",
            "\n",
            "\n",
            "Step 250, Loss: 2.904097318649292, Elapsed Time: 24.29 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her mom. She loved to her mommy. She was very much. She was very excited to her mommy and said, \"I want to her mommy. She was so excited to her mommy. She asked her mommy. She was so excited to her mommy and said, \"I want to her mommy. She was so happy. She was so happy. She was so happy to her mommy. She was so excited to her mommy. She was so excited to her mommy, \"I'm sorry, \"I'm so happy. She was so happy. She was so happy. She was so happy. She was so happy. She said, \"I'm sorry for a big, \"I'm sorry to her mommy.\n",
            "\n",
            "\n",
            "Step 300, Loss: 2.763806104660034, Elapsed Time: 24.98 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a big, a big dog. The dog named Tim was very happy. One day, a big, the cat named Tim went to the park.\n",
            "Tim was very happy to the park. The cat was very happy and the park. The cat was very happy and the park. The dog was very happy and the park. The cat was very happy to the dog was very happy. The dog. The cat was very happy and the dog was very happy and the dog.\n",
            "\n",
            "\n",
            "Step 350, Loss: 2.709317922592163, Elapsed Time: 24.68 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside and play outside in the park with her favorite toy. One day, Lily's mommy's mommy and she was so excited to her mommy. Lily was so excited to play with her mommy and Lily's mommy and her mommy. Lily's mommy and Lily's mommy and Lily's mommy and Lily's mommy. Lily's mommy told her mommy and Lily's mommy and Lily's mommy and Lily's mommy. Lily's mommy and Lily's mommy. Lily's mommy and Lily was happy to help her mommy and Lily's mommy said Lily's mommy and Lily's mommy and Lily's mommy. Lily's mommy and Lily's mommy. Lily's mommy and Lily's mommy and Lily's mommy. Lily's mommy and Lily's mommy. Lily's mommy's mommy and Lily's mommy. Lily's mommy's mommy and Lily's mommy and Lily's mommy. Lily's mommy. Lily's mommy and Lily's mommy. Lily's mommy's mommy's mommy's mommy's mommy and Lily! Judges Judges Judges\n",
            "\n",
            "Step 400, Loss: 2.6059298515319824, Elapsed Time: 25.96 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the park. One day, she was playing in the park. She was so excited and saw a big, so she was very sad. \n",
            "\"Look, Lily. \"I don't worry, I can't know what to do. I can't have to do. \"I can do you.\"\n",
            "\"I can make a big, but she said, \"I can make you.\"\n",
            "\"I can make a moment and said, \"I can make you.\"\n",
            "Lily and said, \"I don't have to be careful. I can make you.\"\n",
            "Lily was so happy to her mom and said, \"I don't you can make you.\"\n",
            "\n",
            "\n",
            "Step 450, Loss: 2.4844841957092285, Elapsed Time: 24.89 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and play. One day, she saw a big tree. She wanted to play with her toys and put it in the box.\n",
            "\"Wow, Lily, Lily, Lily, but it was too.\n",
            "\"Wow, Lily, Lily, I'm so happy that it's okay, but it was too.\n",
            "\"I'm sorry, it's important to be careful.\n",
            "\"I'm sorry for you.\n",
            "Lily, it's important to be careful. She said, but it was happy that it was happy to be careful.\n",
            "\n",
            "\n",
            "Step 500, Loss: 2.4381191730499268, Elapsed Time: 24.80 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She was very happy and she loved to play with her friends. One day, she went to the park to play with her friends.\n",
            "As they saw a big, Lily's friends. Lily was very happy and said, \"Hi, Lily. I'm sorry, Lily. I'm so happy to play with you. I want to play with her friends.\n",
            "Lily and said, \"Yes, Lily. I'm glad you can't have a good friend.\" Lily said, \"Yes, Lily. You're welcome, Lily. You can't have to play with you.\"\n",
            "Lily and said, \"I'm glad you.\"\n",
            "Lily and said, \"Thank you, I'm glad you.\" Lily said, \"Thank you, Lily. I'm glad you, Lily. I'm glad you.\"\n",
            "Lily and said, \"Thank you, Lily. You're welcome, Lily. I love to play with your friends. You're welcome, Lily. You're welcome, Lily and Lily.\n",
            "\n",
            "\n",
            "Step 550, Loss: 2.4573235511779785, Elapsed Time: 25.73 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the park with her friends. One day, she found a big, shiny ball. She was so excited to play with her friends.\n",
            "Lily was so excited to play with her friends. She said, \"I'm going to the ball!\"\n",
            "Lily was so excited to the ball. She said, \"I'm going to the ball!\"\n",
            "Lily was so excited to go to the ball. She was so happy to the ball. She said, \"I'm so much fun!\"\n",
            "\n",
            "\n",
            "Step 600, Loss: 2.3884432315826416, Elapsed Time: 25.25 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play in the park. One day, she saw a big, shiny red ball. She wanted to play with it. She asked her mom, \"Mom, Lily, Lily, Lily. It's not nice.\"\n",
            "Lily was sad and said, \"I want to play with it.\" Lily. She said, Lily. She didn't know what to do. She was sad and sad. She wanted to play with her toys.\n",
            "Lily's mommy said, \"I want to play with you can play with me.\" Lily was sad and said, \"I want to play with you can play with you.\"\n",
            "Lily was happy. She said, \"I can play with you can play with you can play with me.\"\n",
            "Lily's mommy smiled and said, \"I love you. I have fun.\" Lily and said, \"You can play with you can play with you.\"\n",
            "Lily and Lily. She said, \"You are very happy. I have fun.\" Lily. She said, \"You are not nice.\" Lily. She said, \"It's not nice. I have fun. I have fun.\"\n",
            "Lily and Lily. I! Judges Judges Judges\n",
            "\n",
            "Step 650, Loss: 2.2444379329681396, Elapsed Time: 26.41 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Sally. Sally was very excited to go to the store. Sally was very excited to go to the store and find the store.\n",
            "When Sally was walking, Sally saw a big, Sally. Sally was so excited to see what was inside. Sally was going to the store. Sally was so excited to buy the store. Sally was so excited to buy the store to buy the store. Sally was so excited to buy the store. Sally was so excited to buy the store.\n",
            "When Sally was finished baking, Sally was so excited to buy the store. Sally was so excited to buy the store to buy the store. Sally was so happy to buy the store. Sally was so happy to buy the store.\n",
            "\n",
            "\n",
            "Step 700, Loss: 2.271686315536499, Elapsed Time: 25.47 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and make pretty toys. One day, she was playing with her dolls. She was so excited to see her dolls, but she didn't like her.\n",
            "Lily's mommy said, \"Mommy, Lily, I'm so pretty that I'm going to the store to buy some candy. I'm so much.\"\n",
            "Lily was so excited and said, \"No, I'm so I don't know you. I'm so I don't like you.\"\n",
            "Lily nodded and said, \"No, I'm so I'm so I don't want to play with you.\"\n",
            "Lily nodded and said, \"No, I'm sorry, I'm sorry, Lily. I'm sorry, Lily. I'm so you don't have to be careful.\"\n",
            "Lily nodded and said, \"No, Lily. I'm sorry, I'm sorry, Lily. I'm sorry, I'm sorry, Lily. I'm sorry, Lily. I'm sorry, Lily.\"\n",
            "Lily smiled and said, \"I'm sorry, I'm sorry, I'm sorry. I'm sorry, you did you did you. I'm sorry,! Judges Judges Judges\n",
            "\n",
            "Step 750, Loss: 2.21468186378479, Elapsed Time: 26.54 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Jane. She loved to play with her toys and play with her toys. One day, Jane decided to go to the park with her mom and daddy. She asked her mom if she could go to the park and daddy, but she could play with her.\n",
            "\"Mommy, Jane, Jane, but she said yes and they got to the park.\n",
            "\"Mommy, Jane, but it's a big slide!\" Jane said.\n",
            "\"I'm so she said. I have a big slide and you're so much fun!\"\n",
            "Jane smiled and said, \"Yes, I'm so you can't go to the park.\"\n",
            "Jane smiled and said, \"Yes, I have a new friend.\"\n",
            "\n",
            "\n",
            "Step 800, Loss: 2.1084048748016357, Elapsed Time: 25.45 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl who loved to play in the park. She would always run and play in the park. One day, she saw a big, a big, a big, a big, a little girl who was playing with a big, and she wanted to play with her friends. The girl was so excited and she asked her mom if she could play with her mom said yes. Her mom said yes and they were so happy.\n",
            "The girl was so happy to have a big smile on the girl. She said, \"I'm so brave and you have a great job. I have a great idea. I have a great idea. I have a great time.\"\n",
            "The girl was so happy and she said, \"Thank you, I'm so brave. I'm glad you.\"\n",
            "The girl smiled and said, \"Yes, you can play with me. I have a great job. I have a great time. I have a great idea. I have a great time.\"\n",
            "The girl smiled and said, \"Yes, you can play with the girl. I have a big smile. I have a great time. I have a great day. I have a big boy and the girl. I have a great day.! Judges Judges Judges\n",
            "\n",
            "Step 850, Loss: 2.1008241176605225, Elapsed Time: 26.75 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little boy named Timmy. Timmy loved to play with his toys. He would run around his room. One day, Timmy's mommy's mommy's mommy's mommy. Timmy was very sad. Timmy was very sad.\n",
            "Timmy's mommy's mommy's mommy's mommy. She asked him to help him. Timmy's mommy's mommy's mommy's mommy's mommy's mommy. Timmy was happy and daddy told him to be careful when they were going to go to the store. Timmy's mommy's mommy's mommy's mommy's mommy's mommy and daddy told him to be careful when they were going to buy him to buy him.\n",
            "\n",
            "\n",
            "Step 900, Loss: 2.088407516479492, Elapsed Time: 25.55 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little boy named Timmy. Timmy loved to play with his toys and run around in the park. One day, Timmy's mommy saw a big, red ball that it was a ball. Timmy wanted to play with it, but it was too fast.\n",
            "Timmy didn't know what to do. He wanted to play with it, but he didn't want to play with it. He tried to run away, but he didn't want to play with it. He tried to run away, but he didn't want to play with his toy car.\n",
            "Timmy tried to run away, but he didn't want to play with his toy car. He tried to run away, but he didn't want to play with his toy car. He tried to run away, but he didn't want to play with his toy car. He was sad and he didn't want to play with his toy car.\n",
            "\n",
            "\n",
            "Step 950, Loss: 2.1670713424682617, Elapsed Time: 26.07 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys, but she was too big. One day, she saw a big, shiny rock. She wanted to play with it, but she was too big. She wanted to play with it, but she was too fast.\n",
            "Lily's mom said, \"Don't worry, I will help you. I will help you find it.\"\n",
            "Lily was sad and didn't know what to do. She wanted to help her mom. She found a toy that was broken. She put on the rock and put it on the rock. She put it on the rock and put it on it.\n",
            "Lily was happy to see the rock. She had a new rock. She was so happy that she could help her mom. She hugged her mom and said, \"Thank you for helping me, Lily. You are a good friend.\"\n",
            "\n",
            "\n",
            "Step 1000, Loss: 1.9462499618530273, Elapsed Time: 25.81 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her friends. One day, Lily's mommy and daddy were playing in the park. They saw a big slide and wanted to play.\n",
            "Lily asked her mommy if they could go to the slide and play with the slide. She said yes and they got to the slide and they got to the slide. Lily was so excited and started to cry.\n",
            "Lily's mommy said, \"Don't worry, Lily. It's okay, Lily. It's okay to go to the slide and get a band-aid on the slide and it's knee. She was so happy to have her new slide and they all the slide.\n",
            "\n",
            "\n",
            "Step 1050, Loss: 2.021574020385742, Elapsed Time: 25.45 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and play in the park. One day, Lily's mom told her to be careful when she was playing with her toys. Lily was so happy and she decided to play with her toys. She put them in her room and went to play.\n",
            "As she was playing, she saw a big, red ball. She was so excited to play with it. She ran to her mom and dad. They were so happy that they had a new toy. Lily was so happy that she had made her new toy. She had so much fun playing with her toys and playing with her toys.\n",
            "\n",
            "\n",
            "Step 1100, Loss: 1.9811344146728516, Elapsed Time: 25.23 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She was very happy and loved to play with her friends. One day, she was playing with her friends. One day, Lily's friends decided to play hide-and-seek. They all played hide and seek. Lily was so happy that she could play with her friends.\n",
            "After a while, Lily and her friends were playing hide-and-seek. They all played together and had a lot of fun. Lily was happy that she had found a new game. She was so happy that she had made her friends.\n",
            "\n",
            "\n",
            "Step 1150, Loss: 1.9569061994552612, Elapsed Time: 25.04 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One day, Lily went to the park with her mommy.\n",
            "As they were walking, Lily saw a big, scary dog. Lily asked her mommy if she could go to the park.\n",
            "\"Mommy, can we go to the park?\" Lily asked.\n",
            "\"Sure,\" her mommy replied.\n",
            "\"Yes, it's time to go home,\" Lily replied.\n",
            "They walked around the park and saw a big tree. Lily and her mommy were so excited.\n",
            "\"I'm so glad we can't wait for the rest of the park,\" Lily said.\n",
            "\"I'm so glad we can't wait for you.\"\n",
            "\n",
            "\n",
            "Step 1200, Loss: 1.8933675289154053, Elapsed Time: 25.66 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play in the park. One day, she saw a big tree. She wanted to play with it, but she was too high.\n",
            "Lily asked her mom if she could help. Her mom said yes, and Lily was happy. She said yes, and they went to the park.\n",
            "Lily was so excited to play. She had a great time. She had a great time. She said goodbye to the tree and went home. She went back to the park.\n",
            "\n",
            "\n",
            "Step 1250, Loss: 1.9070720672607422, Elapsed Time: 25.14 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily went to the park with her mom. They saw a big, red ball. The ball was very pretty and wanted to play with it.\n",
            "Lily said, \"Mom, can I have a toy?\" Her mom said, \"Yes, I can't buy it. Let's go.\"\n",
            "Lily and her mom went to the park. They played with the ball and had fun. They played together and had fun. Lily was happy to have fun.\n",
            "\n",
            "\n",
            "Step 1300, Loss: 1.9801000356674194, Elapsed Time: 25.02 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big tree with a tree. She wanted to pick it up and see it.\n",
            "Lily asked her mommy if she could go on the tree. Her mommy said yes and they went to the tree. Lily was so happy and thanked her mommy for the tree. She gave her a big tree to eat.\n",
            "\n",
            "\n",
            "Step 1350, Loss: 1.816097617149353, Elapsed Time: 25.09 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around her room. One day, Lily's mommy told her to be careful and not to break any toys. Lily didn't want to hurt her mommy, but her mommy said they needed to be careful.\n",
            "Lily didn't want to be careful and not to break them. She asked her mommy if they could go to the hospital. Her mommy said yes and they went to the hospital. Lily was happy and excited to see her mommy's office. She said they could go to the hospital and play with her friends.\n",
            "Lily was happy to see her friends and they played together. They had a fun day and a fun playing together. Lily was happy to have fun playing with her friends and they all played together. They had a great time playing together and had a fun playing together.\n",
            "\n",
            "\n",
            "Step 1400, Loss: 1.8482478857040405, Elapsed Time: 25.75 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and play in the park. One day, she saw a big, scary dog. The dog was scared and wanted to play with it.\n",
            "Lily ran to the dog, but it was too fast. She ran away from the dog, but it was too late. Lily was sad. She didn't know what to do. She wanted to play with her.\n",
            "Lily's mommy said, \"Don't worry, Lily. I will help you. I will help you.\" Lily felt better and said, \"I will help you. I will help you.\"\n",
            "Lily felt better and said, \"Thank you, Lily. I will help you.\" She said, \"You're welcome, Lily. I will help you.\"\n",
            "Lily and her mom went to the park. They played together and had lots of fun. Lily was happy to help her mom. She said, \"Thank you, Lily. You are a good friend. You are a good friend.\"\n",
            "\n",
            "\n",
            "Step 1450, Loss: 1.8048455715179443, Elapsed Time: 26.39 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around her room. One day, she saw a big, scary cat in the house. The cat was scared and ran away.\n",
            "Lily ran to her friend, Tim, saw a big dog. The dog barked and ran away. Lily was scared and ran away. She ran to him and said, \"Don't worry, Lily. I will help you.\"\n",
            "Tim and Lily played together and Tim played together all day long. They were happy to have found a new toy. They played together and had a fun day.\n",
            "\n",
            "\n",
            "Step 1500, Loss: 1.83536696434021, Elapsed Time: 25.21 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big, scary bug on the ground. She wanted to know what it was, so she ran to her mom and said, \"Mommy, can I come back?\"\n",
            "Her mommy smiled and said, \"Sure! Let's go inside and play with the bug.\"\n",
            "Lily was sad, but she was still sad. She didn't want to play with her friends, but she didn't want to play with her friends. She wanted to play with her friends, but she didn't want to play with her friends. So, she went back home and played with her friends.\n",
            "\n",
            "\n",
            "Step 1550, Loss: 1.7815500497817993, Elapsed Time: 25.35 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her friends. One day, she saw a big, scary monster. The monster wanted to play with it, but Lily didn't want to be scared.\n",
            "Lily tried to run away, but she didn't listen. She tried to run away, but she was too fast. She tried to catch the monster, but she was too fast. She tried to catch the monster, but she was too fast.\n",
            "Lily tried to catch the monster, but she was too fast. She tried to catch the monster, but it was too fast. She tried to catch the monster, but it was too high. She tried to catch it, but it was too fast.\n",
            "Then, she remembered the monster had an idea. She tried to catch the monster, but it was too fast. She tried to catch the monster again, but it was too fast. She tried to catch the monster again, but it was too fast.\n",
            "\n",
            "\n",
            "Step 1600, Loss: 1.793436050415039, Elapsed Time: 26.04 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play outside in the sunshine. One day, she saw a big, scary bug on the ground. She wanted to touch it, but it was too high for her. \n",
            "Lily ran to her mom and dad, but she was scared. She asked her mom if she could go. Her mom said yes, but Lily was scared. She said yes, but she was too scared.\n",
            "The next day, Lily went to the hospital. She saw the bug and it was gone. She asked her mom if she could go back to the hospital. Her mom said yes, but Lily was too scared.\n",
            "The doctors said that the bug was okay. Lily was sad and didn't know what to do. So, but Lily didn't listen to her mom.\n",
            "The doctors told her mom that her mom was okay. Lily was sad and didn't know what to do. Lily was sad and scared. She said sorry to her mommy was sorry for her mom.\n",
            "\n",
            "\n",
            "Step 1650, Loss: 1.871450424194336, Elapsed Time: 25.95 seconds\n",
            "Generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys, but her favorite was a big dog named Max. Max was a little girl named Lily. Lily loved to play with her toys and play with her.\n",
            "One day, Lily's mom told her that she was not nice. Lily didn't listen to her mom, but Lily didn't listen. Max didn't listen to her and kept playing with her. Lily was sad and didn't want to play with her toys anymore.\n",
            "Later that day, Lily's mom saw her crying and asked her what happened. Lily told her that she had accidentally broke her toy and she accidentally broke it. Lily was sad and cried out loud. She cried and cried a lot.\n",
            "Her mom came and hugged her. Lily felt sorry for her and said sorry. Lily felt sorry and promised to help her mom and not let her play with her. From that day on, Lily learned that sometimes things can be kind and not be kind to others.\n",
            "\n",
            "\n",
            "Step 1700, Loss: 1.7056902647018433, Elapsed Time: 26.56 seconds\n",
            "Generated text:\n",
            "Once upon a time, a little girl named Lily went to the park with her mom. Her mom said, \"Mommy, can we go on an adventure?\" Lily said, \"Sure, but be careful. Let's go on an adventure.\" \n",
            "So they went to the park and saw a big slide. Lily wanted to go on the slide, but she was too high. \n",
            "Suddenly, the little girl started to feel dizzy. She started to cry. \n",
            "Her mommy said, \"Don't worry, Lily. We can go to the slide and see if we can go.\" \n",
            "Lily was so excited to go on the slide. She was so excited to go on the slide and she ran to the slide. \n",
            "When she got there, she saw a big slide. She was so excited to see her mommy and she was so excited to see her. She was so excited to go on the slide and see her mommy. \n",
            "When they got there, Lily was so happy to see her mommy. She was so excited to go on the slide and she was so excited to go. She was so excited to go on the slide and get up. She was so happy to see her mommy. She! Judges Judges Judges\n",
            "Final generated text:\n",
            "Once upon a time, there was a little girl named Lily. She loved to play with her toys and make her friends. One day, she saw a big box of crayons. She wanted to make it look pretty. She asked her mom if she could have it. Her mom said yes, but Lily was very happy.\n",
            "Lily's mom saw the crayon and said no. She said it was a good idea. She said it was a good idea. She took a big bite and it was a good idea. She took a big bite and it was a good idea. She took a big bite and it was a good idea. She took a big bite and it was a good idea. She took a bite and it was a good idea. She took a bite and it was a bit better. She was so happy that she could make her mom.\n"
          ]
        }
      ],
      "source": [
        "model = create_model(rngs=nnx.Rngs(0))\n",
        "optimizer = nnx.Optimizer(model, optax.adam(1e-3))\n",
        "metrics = nnx.MultiMetric(\n",
        "  loss=nnx.metrics.Average('loss'),\n",
        ")\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "start_prompt = \"Once upon a time\"\n",
        "start_tokens = tokenizer.encode(start_prompt)[:maxlen]\n",
        "print(f\"Initial generated text:\")\n",
        "generated_text = model.generate_text(\n",
        "    maxlen, start_tokens\n",
        ")\n",
        "\n",
        "metrics_history = {\n",
        "  'train_loss': [],\n",
        "}\n",
        "\n",
        "prep_target_batch = jax.vmap(lambda tokens: jnp.concatenate((tokens[1:], jnp.array([0]))))\n",
        "\n",
        "step = 0\n",
        "\n",
        "start_time = time.time()\n",
        "for batch in text_dl:\n",
        "    if len(batch) % len(jax.devices()) != 0:\n",
        "      continue  # skip the remaining elements\n",
        "    input_batch = jnp.array(jnp.array(batch).T)\n",
        "    target_batch = prep_target_batch(input_batch)\n",
        "    train_step(model, optimizer, metrics, (input_batch, target_batch))\n",
        "\n",
        "    if (step + 1) % 50 == 0:\n",
        "      for metric, value in metrics.compute().items():\n",
        "          metrics_history[f'train_{metric}'].append(value)\n",
        "      metrics.reset()\n",
        "\n",
        "      elapsed_time = time.time() - start_time\n",
        "      print(f\"\\n\\nStep {step + 1}, Loss: {metrics_history['train_loss'][-1]}, Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "      start_time = time.time()\n",
        "\n",
        "      print(f\"Generated text:\")\n",
        "      generated_text = model.generate_text(\n",
        "          maxlen, start_tokens\n",
        "      )\n",
        "\n",
        "    step += 1\n",
        "\n",
        "# Final text generation\n",
        "print(f\"\\nFinal generated text:\")\n",
        "generated_text = model.generate_text(\n",
        "    maxlen, start_tokens\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thaLs6TD0lt5"
      },
      "source": [
        "Visualize the training loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "B6Eg1Cz2y_iP",
        "outputId": "f06231fe-61bf-4f45-cc7b-7624e7d00498"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(metrics_history['train_loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB-ExEt1Zl1C"
      },
      "source": [
        "As you can see, the model goes from generating completely random words at the beginning to generating sensible tiny stories at the end of the training. So essentially we have pretrained a small LLM to write tiny stories for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soPqiR1JNmjf"
      },
      "source": [
        "## Saving the checkpoint\n",
        "\n",
        "Save the model checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkoFGCgSZ1yz",
        "outputId": "61d736d3-369c-49c0-f156-6ccb536de5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array_metadatas       d\t\t      _METADATA        _sharding\n",
            "_CHECKPOINT_METADATA  manifest.ocdbt  ocdbt.process_0\n"
          ]
        }
      ],
      "source": [
        "import orbax.checkpoint as orbax\n",
        "\n",
        "state = nnx.state(model)\n",
        "\n",
        "checkpointer = orbax.PyTreeCheckpointer()\n",
        "checkpointer.save('/content/save', state)\n",
        "\n",
        "# Make sure the files are there\n",
        "!ls /content/save/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,md:myst"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}